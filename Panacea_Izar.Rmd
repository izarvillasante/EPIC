---
title: "Dietary polyphenol and obesity markers. Translational research"
author: "Izar de Villasante, Brainvitge"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
#runtime: shiny
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    keep_tex: yes
    toc: yes
    toc_depth: 3
params:
  
  
  
  
  main_folder: !r getwd()
  #/home/izar/notebooks/
  
  men_color: "aquamarine"  #hcl(h=60,c=100,l=65) 
  women_color: "indianred1"      #hcl(h=15,c=100,l=65) #"#ED813E" # 
  results: ./Results
  Datasets: ./Datasets
  mercedes: "EPIC.PANACEA_log2_factors" 
  excel_local: "Local_Measures.xlsx"
  variables: [vol]
    
header-includes: 
  - \usepackage{bbm}
  - \usepackage[spanish]{babel}
---
\newline
\newline

---

```{r setup, include=FALSE}
require(knitr)
#rmarkdown::render("panacea.Rmd", params = "ask")

# include this code chunk as-is to set options
opts_chunk$set(comment = NA, prompt = TRUE, tidy = FALSE, 
               fig.width = 10, fig.height = 10,echo = TRUE, 
               message = FALSE, warning = FALSE, cache=FALSE)
Sys.setlocale("LC_TIME", "C")
```

```{r paquetes, include=FALSE}
if(!(require(faraway))) install.packages("faraway")
if(!(require(devtools))) install.packages("devtools")
if(!(require(lmerTest))) install.packages("lmerTest")
if(!(require(ggplot2))) install.packages("ggplot2")
if(!(require(ggpubr)))install.packages("ggpubr")
if(!(require(grid)))install.packages("grid")
if(!(require(gtable)))install.packages("gtable")

if(!(require(gtools)))install.packages("gtools")
 
if(!(require(printr))) {
  install.packages(
    'printr',
    type = 'source',
    repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
  )
}
```

# Project context:

El objetivo principal del estudio es evaluar la asociación entre la exposición de polifenoles y los marcadores de obesidad e investigar su efecto sobre los parámetros de salud y la pérdida ponderal en un tratamiento de adelgazamiento. El proyecto consta de tres fases: i) evaluación de la exposición de polifenoles, medidos mediante cuestionarios de dieta, biomarcadores o la combinación de ambas medidas, y el cambio de peso y perímetro de cintura en un gran estudio epidemiológico observacional: EPIC-PANACEA, que incluye ~370000 adultos provenientes de 10 países europeos, con un seguimiento de 2 a 11 años.

*The main objective is to evaluate the association between polyphenol exposure and obesity markers and to investigate their effect on several health markers and the body weight composition in a weight loss treatment. The Project is divided in 3 stages: i) Firstly, to evaluate the association between the exposure of polyphenols, assessed using dietary questionnaires, biomarkers or the combination of both methods, and the change in body weight and waist circumference in a large observational study: the EPIC-PANACEA. It consists in ~370000 adult men and women from ten European countries with a follow-up ranged from 2 to 11 years.*

# Data Preparation:
## Load data

The first step is always to load the data. In this case the startingpoint is a database containing the polifenol intake from the Panacea project

```{r load data ,cache=False}
#First save current working directory:
cwd <- getwd()
#Load Datasets folder:
datasets <- paste(cwd,"Datasets/",sep="/")

#Load each file:

file1 <- "bdpanacea_reduced.txt"
file2 <- "weight.sas7bdat"
file3 <- "polifenoles_panacea.sas7bdat"
file4 <- "dq_pp_such_2014.sas7bdat"


#reduced <- read.table("Z:/Rstudio/EPIC/bdpanacea_reduced.txt", quote="\"", comment.char="")
if(!exists("main_db")){
  main_db <- haven::read_sas(paste0(datasets,file2))
}
```


It is a very big dataset, let's take a quick look:
```{r}
dim(main_db)
pryr::object_size(main_db)
```
A total of 349165 participants from the "Epic-Panacea" project with consumption data of polifenols. A big dataset of 1.78GB
A total of 628 colums containing polifenol intake and other information that can be grouped as follows:

1. The first step is to convert the dataframe into a data.table. In order to make faster ops and easier to work. And most important save us RAM.
```{r}
library(data.table)
tbl<-setDT(main_db)
```


2. Now lets separate the columns containing general info such as Age, weight, etc. From the columns containing polifenols:

```{r}
general <- tbl[, .SD, .SDcols = c(1:3,490:555,622)]
```
```{r}
str(general)

```

Now the data.table `general` contains all the descriptive variables. The next step is to convert those categorical into factors. We will use the fact that all the categorical variables contain the attribute "format.sas" in this case: 

```{r}
#fkt <- function(variable){
#  any(names(attributes(variable)) %in% "format.sas" == TRUE) 
#  }
#cols_idx <- unlist(lapply(general,fkt),use.names = FALSE)
#cols <- names(general)[cols_idx]

#general[, (cols) := lapply(.SD,factor),.SDcols=cols]


```

Or a one liner:
```{r}
general <- general[, lapply( .SD , function(x) if( any(names(attributes(x)) %in% "format.sas" == TRUE)){factor(x)}else{x})]

```

Now we have some continuos variables and some categorical variables. In order to plot this dataset with ggplot2, it must be transformed so that all the variables have a single continuous value for each continuos variable and the 5y weight change:

```{r}
descriptive <- melt(general, id.vars = c(names(general)[sapply(general,is.factor)],"Weight_change_5y"))
str(descriptive)
```
As you can see the categorical variables and the Weight_change_5y have their own column and all the continuos variables have been transformed into 2 new columns:
- variable: contains the name of the continuos variable
-Value: contains the value of the continuos variable.

```{r}
levels(descriptive$variable)
```


Therefore, each row contains one unique numeric/continuos value plus all the categories to which it belongs and the 5y weight change value we will use as dependent variable. Now we can easily plot these datasets.   

```{r, CACHE=TRUE}
library(ggplot2)
ggplot(descriptive, aes(x = value, y = Weight_change_5y)) +
  geom_point() + facet_wrap(~variable, scale="free")
```


Let's have a look to the different variables.
```{r,cache=TRUE}
library(ggplot2)
p <- ggplot(descriptive, aes(factor(variable), value)) 
p + geom_boxplot() + facet_wrap(~variable, scale="free")

```

# Polifenol log normalization:
The log transformation, which is a member of the Box–Cox transformation family (Box and Cox 1964), has become the most commonly used transformation in biomedical,
public health.

```{r}
polifenols <- tbl[, .SD, .SDcols = 4:422]
```

```{r}
poli_plot <- cbind(polifenols,main_db$Weight_change_5y)
```


# Adding an arbitrary low constant c = 0.0000001:
```{r}
#general <- general[, lapply( .SD , function(x) if( any(names(attributes(x)) %in% "format.sas" == TRUE)){factor(x)}else{x})]
l1 <- polifenols[,lapply(.SD,function(x) log2(x+0.0000001))]
```

```{r}
l1_plot <- cbind(l1,"Weight_change_5y"=main_db$Weight_change_5y,"Center"=main_db$Center)
ggplot(aes(x=PP_012,y=Weight_change_5y),colour=factor(Center),data=l1_plot) + geom_point(size=2)  + geom_smooth(method="lm",colour="red")

```



```{r}

l1_melt <- melt(l1_plot, id.vars = "Weight_change_5y")

```

```{r}
library(ggplot2)
l1_plot_multi <- ggplot(l1_melt, aes(x = value, y = Weight_change_5y)) +
  geom_point() + facet_wrap(~variable, scale="free")

```
```{r}
l1_plot_multi
```


#Adding half of the lowest non-zero:
```{r}
l2 <- polifenols[,lapply(.SD,function(x) log2(x+ min(x[x>0])/2))]
```

#Adding the value that minimize variance:
This model follows the procedure described in  John Paul Ekwaru & Paul J Veugelers (2018) The Overlooked Importance of
Constants Added in Log Transformation of Independent Variables with Zero Values: A Proposed
Approach for Determining an Optimal Constant, Statistics in Biopharmaceutical Research, 10:1,
26-29, DOI: 10.1080/19466315.2017.1369900

https://doi.org/10.1080/19466315.2017.1369900

```{r}
Y <- general$Weight_change_5y
X <- polifenols$PP_012
#m <- nls(Y ~ b0 + b1 * log(X+C),start = list(b0=1, b1=1,C=0.00001))
#coef(m)["C"]
tau <- function(x){
  Y <- general$Weight_change_5y
  m<-nlsLM(Y ~ b0 + b1 * log(x+C),start = list(b0=1, b1=0.5,C=0.0001))
  return(coef(m)["C"])
}

l3 <- polifenols[,lapply(.SD,function(x) log2(x + tau(x)))]
 
```

# Square root to deal with 0:

```{r}
l4 <- polifenols[,lapply(.SD,function(x) sqrt(x))]
```




3. [423:459] From column 423 to 459 we have 37 main subclasses of polifenols:

```{r}
names(main_db)[423:459]
PP_subclass <- names(main_db)[423:459]
#PP_subclass_db <- main_db[,423:459]
length(PP_subclass)
```

4. [460:497] From 460 to 487 there are 28 subclasses of polifenols previously divided into quintiles.

```{r}
names(main_db)[460:487]
PP_subclass_q5 <- names(main_db)[460:487]
#PP_subclass_q5_db <- main_db[,460:487]
length(PP_subclass_q5)

```
For some reason there are some differences between the subclasses of one set and the other:

```{r}
# gsub(".*n5_", "", PP_subclass_q5) #Removes n5_ from all occurences in string
setdiff(PP_subclass, gsub(".*n5_", "", PP_subclass_q5))

```
There are 13 differences between subclasses. Since there are only 9 more subclasses without quantile, this may be because a spelling error:

```{r}
setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )
wrong_names <- setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )

```
As previously suggested there are 4 quantized subgroups misspelled without capital letter.
Let's correct this mistake:

```{r}
capwords <- function(s, strict = FALSE) {
    cap <- function(s) paste(toupper(substring(s, 1, 1)),
                  {s <- substring(s, 2); if(strict) tolower(s) else s},
                             sep = "", collapse = " " )
    sapply(strsplit(s, split = " "), cap, USE.NAMES = !is.null(names(s)))
}


names_to_correct <-paste0("n5_",wrong_names) 
names_to_correct
which(names(main_db) %in% names_to_correct)


names_to_correct_ok <- paste0("n5_", capwords(wrong_names))
names_to_correct_ok

names(main_db)[which(names(main_db) %in% names_to_correct)] <- names_to_correct_ok

```
Now we can check again which subgroups are transformed into quintiles.


```{r}
names(main_db)[460:487]
PP_subclass_q5 <- names(main_db)[460:487]
#PP_subclass_q5_db <- main_db[,460:487]
length(PP_subclass_q5)

```

```{r}
# gsub(".*n5_", "", PP_subclass_q5) #Removes n5_ from all occurences in string
setdiff(PP_subclass, gsub(".*n5_", "", PP_subclass_q5))

```
Still there are 2 more than there should be.

```{r}
setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )
wrong_names <- setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )

```
Here the problem is pp instead of PP in subclass and in class PP is missing let's recode it: 

```{r}
names_to_correct <-paste0("n5_",wrong_names) 
names_to_correct
which(names(main_db) %in% names_to_correct)


names_to_correct_ok <- c("n5_Other_PP_subclass","n5_Other_PP_class")
names_to_correct_ok
```


```{r}
names(main_db)[which(names(main_db) %in% names_to_correct)] <- names_to_correct_ok

```

Now let's check again:

```{r}
names(main_db)[460:487]
PP_subclass_q5 <- names(main_db)[460:487]
length(PP_subclass_q5)
setdiff(PP_subclass, gsub(".*n5_", "", PP_subclass_q5))

```
```{r}
setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )
```
Now they are correctly named.
The string `PP_subclass_notq5` will contain those variables which are not transformed into quantiles:

```{r}
PP_subclass_notq5 <- setdiff(gsub(".*n5_", "", PP_subclass_q5), PP_subclass )
```


It is convenient to maintain the same criteria for nomenclature when deciding subclasses.
My personal recomendation is to ignore this pre-build classes and create a new quantization in case it is required.

```{r}


quintile <- function(x) cut(x,
                            breaks = unique(quantile(x, c(0, 0.20, 0.4, 0.6, 0.8, 1))),
                            ordered_result = TRUE,
                            right=FALSE,
                            include.lowest = T,
                            labels =F,
                            type=3
)
PP_quintile <- data.frame(apply(main_db[,PP_subclass],2,quintile))
str(PP_quintile)


                 
#PP_subclass_q5_db <- gtools::quantcut(main_db$Anthocyanins,5)
```

```{r}
quantile(main_db$Theaflavins, c(0, 0.20, 0.4, 0.6, 0.8, 1))
```

There are some variables that have repeated quantile values. This results in repeted value for cuts, which makes fewer cuts. The solution is to increase the number of groups until 5 groups are formed. This is what the function cut2 makes. Allowing the same number of groups for all the variables.

```{r}
factor(Hmisc::cut2(main_db$Anthocyanins, g=5,m=5,minmax=T,include.lowest = TRUE))
```


```{r}
#factor(Hmisc::cut2(main_db$Theaflavins, g = 4), labels = c(1:4))

quintile <- function(x) factor(Hmisc::cut2(x,g=5,exclude=0,labels=c(1:4)))

PP_quintile <- data.table(apply(main_db[,PP_subclass],2,quintile))
#str(PP_quintile)
```
```{r}
library(data.table)
dtsetDT(PP_quintile)
PP_quintile[.SD , quartile := floor( 1 + 4 * (.I-1) / .N)]
```



6.Separate all polifenols:

```{r}
polifenoles <- datos[,4:422]
```

We are going to normalize the polifenols using different transformations

 1.- Logaritmic transformation:
Logaritms need a gamma coefficient in order to deal with 0. In order to choose this value we are going to check wich is the smallest value in all the dataset


```{r}
min(polifenoles[polifenoles != 0])
which.min(polifenoles[polifenoles != 0],polifenoles != 0)
```


## Data preparation:

